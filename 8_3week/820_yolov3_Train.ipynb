{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ultralytics_yolov3_train.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ol6t9VaN9Moo"
      },
      "source": [
        "# Ultralytics Yolo v3 Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CeN01y3E9V1w",
        "outputId": "3719f682-3a23-4ebd-ba45-87b48fc04e3f"
      },
      "source": [
        "# Ultralytics ì„¤ì¹˜\n",
        "!git clone https://github.com/ultralytics/yolov3\n",
        "!cd yolov3; pip install -qr requirements.txt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'yolov3'...\n",
            "remote: Enumerating objects: 9862, done.\u001b[K\n",
            "remote: Total 9862 (delta 0), reused 0 (delta 0), pack-reused 9862\u001b[K\n",
            "Receiving objects: 100% (9862/9862), 9.19 MiB | 16.01 MiB/s, done.\n",
            "Resolving deltas: 100% (6667/6667), done.\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 636 kB 9.5 MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8fbe8Wl9iv2",
        "outputId": "1c066bd1-b4c2-405f-c948-8859143fba21"
      },
      "source": [
        "from IPython.display import Image, clear_output\n",
        "import torch\n",
        "clear_output()\n",
        "print(f\"Setup complete, Using torch {torch.__version__} \\\n",
        "  ({torch.cuda.get_device_properties(0).name \\\n",
        "    if torch.cuda.is_available() else 'CPU'})\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setup complete, Using torch 1.9.0+cu102   (Tesla T4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ayw6VBtO92yR",
        "outputId": "4b43420c-c64d-4c51-8346-69456914ffd0"
      },
      "source": [
        "%cd yolov3/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/yolov3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhROcfA8-hWm",
        "outputId": "b8a9894d-426e-4a3b-e873-aaafef9a0b2f"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/yolov3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ilcv21a3-ivW"
      },
      "source": [
        "!python train.py --img 640 --batch 8 --epochs 3 \\\n",
        "    --data coco128.yaml --weights yolov3.pt --nosave"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvy8X81pEmHS"
      },
      "source": [
        "# Dataset Config ì™€ Weight íŒŒì¼ì˜ ìƒëŒ€ê²½ë¡œ, ì ˆëŒ€ê²½ë¡œ\n",
        "- train.pyì˜ data optionê°’ìœ¼ë¡œ Dataset config yaml íŒŒì¼ì„ ì§€ì •í•  ìˆ˜ ìˆìœ¼ë©°, íŒŒì¼ëª…ë§Œ ì…ë ¥í•  ê²½ìš°ëŠ” yolov3/data ì—ì„œ í•´ë‹¹ íŒŒì¼ì„ ì°¾ìŒ. ì ˆëŒ€ ê²½ë¡œë¥¼ ì§€ì •í•˜ë©´ í•´ë‹¹ ê²½ë¡œì—ì„œ ì°¾ìŒ.\n",
        "\n",
        "- weights optionì˜ ê²½ìš° íŒŒì¼ëª…ë§Œ ì…ë ¥í•  ê²½ìš° yolov3 ë””ë ‰í† ë¦¬ì—ì„œ í•´ë‹¹ íŒŒì¼ì„ ì°¾ìŒ. í•´ë‹¹ íŒŒì¼ì´ ì—†ì„ ê²½ìš° ìë™ìœ¼ë¡œ ì§€ì •ëœ urlì—ì„œ ë‹¤ìš´ë¡œë“œí•¨. ì ˆëŒ€ ê²½ë¡œë¥¼ ì…ë ¥í•œ ê²½ìš° í•´ë‹¹ ê²½ë¡œì—ì„œ ì°¾ê³ , ì—†ìœ¼ë©´ ìë™ ë‹¤ìš´ë¡œë“œ í•¨.\n",
        "\n",
        "- weightsíŒŒì¼ì€ yolov3.pt, yolov3-tiny.pt, yolov3-spp.pt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTPwLA9W_VAW",
        "outputId": "ac5b8eba-5e4d-4699-af03-a7cbe809561e"
      },
      "source": [
        "%cd /content"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoUAaJ2_I7-1",
        "outputId": "26ae5c44-822b-4444-ccf1-4c4d5fe9e843"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boCC_kYXI_m_"
      },
      "source": [
        "# !cd yolov3; python train.py --img 640 --batch 8 --epochs 3 \\\n",
        "#     --data coco128.yaml --weights yolov3.pt --nosave --cache\n",
        "# !cd yolov3; python train.py --img 640 --batch 8 --epochs 3 \\\n",
        "#     --data coco128.yaml --weights yolov3-tiny.pt --nosave --cache\n",
        "!cd yolov3; python train.py --img 640 --batch 8 --epochs 3 \\\n",
        "    --data coco128.yaml --weights '' --cfg yolov3.yaml --nosave --cache"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqYOla1nKNsU"
      },
      "source": [
        "# coco128 ë°ì´í„° ë””ë ‰í† ë¦¬ ë³€ê²½í›„ í•™ìŠµ\n",
        "#- /content/data ì•„ë˜ì— coco128 ë°ì´í„° ë‹¤ìš´ë¡œë“œ í›„ í•™ìŠµ ì‹œ\n",
        "!mkdir /content/data\n",
        "!mv -r /content/coco128 /content/data/\n",
        "!wget -O /content/data/coco128/coco128_renew.yaml http://raw.githubusercontent.com/chulminkw/DLCV/master/data/util/coco128_renew.yaml"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvwjjLsxMQJk",
        "outputId": "8e5cd1b0-f81c-47b5-9d31-f97dfed420e9"
      },
      "source": [
        "!cd yolov3; python train.py --img 640 --batch 8 --epochs 3 \\\n",
        "    --data /content/data/coco128/coco128_renew.yaml \\\n",
        "    --weights yolov3.pt --nosave --cache\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov3 âœ…\n",
            "YOLOv3 ğŸš€ v9.5.0-13-g1be3170 torch 1.9.0+cu102 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Namespace(adam=False, artifact_alias='latest', batch_size=8, bbox_interval=-1, bucket='', cache_images=True, cfg='', data='/content/data/coco128/coco128_renew.yaml', device='', entity=None, epochs=3, evolve=False, exist_ok=False, global_rank=-1, hyp='data/hyp.scratch.yaml', image_weights=False, img_size=[640, 640], label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=False, name='exp', noautoanchor=False, nosave=True, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='runs/train/exp5', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=8, upload_dataset=False, weights='yolov3.pt', workers=8, world_size=1)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0\n",
            "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOv3 logging with 'pip install wandb' (recommended)\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     20672  models.common.Bottleneck                [64, 64]                      \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    164608  models.common.Bottleneck                [128, 128]                    \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  8   2627584  models.common.Bottleneck                [256, 256]                    \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  8  10498048  models.common.Bottleneck                [512, 512]                    \n",
            "  9                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            " 10                -1  4  20983808  models.common.Bottleneck                [1024, 1024]                  \n",
            " 11                -1  1   5245952  models.common.Bottleneck                [1024, 1024, False]           \n",
            " 12                -1  1    525312  models.common.Conv                      [1024, 512, [1, 1]]           \n",
            " 13                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
            " 14                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 15                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
            " 16                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 18           [-1, 8]  1         0  models.common.Concat                    [1]                           \n",
            " 19                -1  1   1377792  models.common.Bottleneck                [768, 512, False]             \n",
            " 20                -1  1   1312256  models.common.Bottleneck                [512, 512, False]             \n",
            " 21                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 22                -1  1   1180672  models.common.Conv                      [256, 512, 3, 1]              \n",
            " 23                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 24                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 25           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 26                -1  1    344832  models.common.Bottleneck                [384, 256, False]             \n",
            " 27                -1  2    656896  models.common.Bottleneck                [256, 256, False]             \n",
            " 28      [27, 22, 15]  1    457725  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n",
            "Model Summary: 333 layers, 61949149 parameters, 61949149 gradients, 156.4 GFLOPS\n",
            "\n",
            "Transferred 440/440 items from yolov3.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "Optimizer groups: 75 .bias, 75 conv.weight, 72 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/data/coco128/labels/train2017' images and labels... 128 found, 0 missing, 2 empty, 0 corrupted: 100% 128/128 [00:00<00:00, 3305.14it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data/coco128/labels/train2017.cache\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB): 100% 128/128 [00:00<00:00, 304.92it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/data/coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupted: 100% 128/128 [00:00<?, ?it/s]\n",
            "  0% 0/128 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB):  16% 21/128 [00:00<00:00, 198.71it/s]\u001b[A\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB):  32% 41/128 [00:00<00:00, 192.10it/s]\u001b[A\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB):  48% 62/128 [00:00<00:00, 192.84it/s]\u001b[A\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB):  64% 82/128 [00:00<00:00, 186.98it/s]\u001b[A\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/data/coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupted: 100% 128/128 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB): 100% 128/128 [00:00<00:00, 193.52it/s]\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "Plotting labels... \n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 4.26, Best Possible Recall (BPR) = 0.9946\n",
            "Image sizes 640 train, 640 test\n",
            "Using 2 dataloader workers\n",
            "Logging results to runs/train/exp5\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       0/2     7.33G   0.02774   0.02395  0.007242   0.05893       111       640:   0% 0/16 [00:06<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/jit/_trace.py:730: UserWarning: The input to trace is already a ScriptModule, tracing it is a no-op. Returning the object as is.\n",
            "  \"The input to trace is already a ScriptModule, tracing it is a no-op. Returning the object as is.\"\n",
            "       0/2       12G   0.02976   0.02501  0.008362   0.06314        68       640: 100% 16/16 [00:23<00:00,  1.48s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 8/8 [00:17<00:00,  2.14s/it]\n",
            "                 all         128         929       0.801       0.662       0.788       0.542\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       1/2     7.19G   0.03084     0.025  0.008129   0.06397        86       640: 100% 16/16 [00:07<00:00,  2.29it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 8/8 [00:02<00:00,  3.74it/s]\n",
            "                 all         128         929       0.793       0.668       0.788       0.541\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       2/2     7.19G   0.02896   0.02225   0.01129    0.0625       121       640: 100% 16/16 [00:07<00:00,  2.27it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 8/8 [00:03<00:00,  2.49it/s]\n",
            "                 all         128         929       0.805       0.673       0.796       0.544\n",
            "3 epochs completed in 0.019 hours.\n",
            "\n",
            "Optimizer stripped from runs/train/exp5/weights/last.pt, 124.2MB\n",
            "Optimizer stripped from runs/train/exp5/weights/best.pt, 124.2MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4_dyOnCNGi6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}